---
title: AI 黑话
date: '2025-06-25'
tags: ['AI']
draft: false
summary: 用五岁小孩可以理解的语言解释AI中涉及到的专业术语，收藏这份清单不再被各种名词搞得晕头转向。
---

你可能听到了很多人工智能术语，可能对其中一些的意思有个大概了解…… 但其实并不真正清楚。下面是 20 多个最常见人工智能术语的定义， “像给五岁孩子解释一样” ，这些定义基于我自己的理解、大量研究以及我那些对人工智能最为精通的朋友的反馈。

如果你已经熟知这一切，没关系，这篇文章不适合你。但对其他人来说，下次开会时要是被满场的 AI 行话绕得晕头转向，不妨把下面这份清单放在手边。随着新流行词不断出现，我会持续更新这份列表。

### **模型**

人工智能**模型**是一种被设计成像人类大脑一样工作的计算机程序。你给它一些输入（即提示），它会进行一些处理，然后生成一个响应。

就像孩子一样，模型通过接触大量人们在不同场景下的典型反应或行为示例来 “学习”。随着接触的示例越来越多，它开始识别模式、理解语言，并生成连贯的响应。

人工智能模型有许多不同的类型。有些专注于语言领域，例如 ChatGPT o3、Claude Sonnet 4、Gemini 2.5 Pro、Meta Llama 4、Grok 3、深度求索（DeepSeek）和 Mistral 等，这类模型被称为大型语言模型（LLMs）。其他模型则专为视频设计，比如谷歌的 Veo 3、OpenAI 的 Sora 和 Runway Gen-4。还有一些模型擅长生成语音，例如 ElevenLabs、Cartesia 和 Suno。此外，也存在更传统的人工智能模型类型，如分类模型（用于欺诈检测等任务）、排序模型（用于搜索引擎、社交媒体信息流和广告）以及回归模型（用于进行数值预测）。

### **LLM(large language model) - 大型语言模型**

**LLM（大型语言模型）** 是基于文本的模型，是被设计用于理解和生成人类可读的文本的模型。这就是为什么它的名字进而包含“语言”这个词了。

最近，大多数大型语言模型（LLMs）实际上已演进为 “多模态” 模型，它们不仅能处理和生成文本，还能在单一对话界面中处理和生成图像、音频及其他类型的内容。例如，所有 ChatGPT 系列的大语言模型都原生支持文本、图像甚至语音。这一能力始于 GPT-4o，其中 “o” 代表 “omni”（意为该模型可接受文本、音频和图像的任意组合输入）。

[这是一篇关于大型语言模型（LLMs）实际工作原理的优质入门指南，还有 Andrej Karpathy 撰写的热门深度解析文章](https://youtu.be/zjkBMFhNj_g)

### **Transformer**

2017 年由谷歌研究人员开发的 Transformer 架构，是一项使现代人工智能（尤其是大型语言模型）成为可能的算法突破。

Transformer 架构引入了一种称为 “注意力” 的机制。借助这一机制，模型不再只能按顺序逐词读取文本，而是能够同时关注所有词汇。这有助于模型理解词汇之间的关联，使其在捕捉语义、语境和细微差别方面，远比早期技术更为出色。

Transformer 架构的另一大优势在于其高度可并行性 —— 能够同时处理序列中的多个部分。这使得只需通过扩展数据和计算能力，就能训练出更大、更智能的模型。正是这一突破，让我们从基础聊天机器人一跃进入复杂 AI 助手的时代。如今，几乎所有主流 AI 模型（包括 ChatGPT 和 Claude）都构建在 Transformer 架构之上。

[这是我见过的关于 Transformer 最出色的解释。此外，这里还有一篇更具技术性且配有可视化内容的深度解析](https://youtu.be/KJtZARuO3JY)

### **Training/Pre-training（训练/预训练）**

**训练**是人工智能模型通过分析海量数据进行学习的过程。这些数据可能包括互联网的大量内容、所有已出版的书籍、音频记录、电影、电子游戏等。训练最先进的模型可能需要数周或数月时间，需要处理数万亿字节的数据，成本高达数亿美元。

对于大型语言模型（LLMs），其核心训练方法被称为 “下一个标记预测”。该模型会接触数十亿条文本序列，其中最后一个 “标记”（大致相当于一个单词，具体定义见下文 “标记”）被隐藏，而模型需要学习预测接下来应该出现的单词。

在训练过程中，模型会调整数百万个被称为 “权重” 的内部设置。这类似于人类大脑中的神经元根据经验增强或减弱连接的方式。当模型做出正确预测时，这些权重会得到强化；当预测错误时，权重会被调整。随着时间的推移，这一过程帮助模型提升对事实、语法、推理以及语言在不同语境中运作方式的理解。[这里是直观的简要说明](https://www.youtube.com/watch?v=rEDzUT3ymw4)。


### **Supervised learning（监督学习）**

监督学习是指模型在 “带标签” 的数据上进行训练 —— 即提供正确答案。例如，可能会给模型数千封标记为 “垃圾邮件” 或 “非垃圾邮件” 的电子邮件，模型从中学习识别区分垃圾邮件和非垃圾邮件的模式。一旦完成训练，该模型便可以对从未见过的新邮件进行分类。

包括 ChatGPT 在内的大多数现代语言模型都使用一种称为 “自监督学习” 的子类型。该模型不依赖人类标注的数据，而是通常通过隐藏句子的最后一个标记 / 单词并学习预测它来创建自己的标签。这使它能够从大量原始文本中学习，而无需人工注释。

### **Unsupervised learning（无监督学习）**

无监督学习则与之相反：向模型提供的数据不包含任何标签或答案。其任务是自行发现模式或结构，例如将相似的新闻文章分组，或在数据集中检测异常模式。这种方法常用于异常检测、聚类和主题建模等任务，其目标是探索和组织信息，而非进行特定预测。

### **Post-training（训练后处理）**

训练后指的是在模型训练完成后采取的所有额外步骤，目的是让模型更实用。这些步骤包括 “微调” 和 “强化学习从人类反馈中优化（RLHF）” 等。

### **Fine-tuning（微调）**

微调是一种训练后技术，指的是在已有训练好的模型基础上，使用针对特定目标定制的数据进行额外训练，以使模型在该目标任务上表现更优。例如，你可以用公司的客服对话数据对模型进行微调，使其能以品牌特有的风格响应；或用医学文献数据微调，让模型更擅长回答医疗健康问题；亦或用特定年级的教育内容微调，打造能以适合对应年龄段的方式讲解概念的辅导助手。

这种额外训练会调整模型的内部权重，使其响应针对特定用例实现专业化，同时保留其在预训练阶段所学的通用知识。

[这里是关于微调工作原理的精彩技术深度解析](https://youtu.be/eC6Hd1hFvos)

### **RLHF (reinforcement learning from human feedback)-强化学习从人类反馈中优化**

RLHF（强化学习从人类反馈中优化）是一种训练后技术，它超越了下一个标记预测和微调，通过教 AI 模型以人类期望的方式行事 —— 使其更安全、更有帮助，并与我们的意图保持一致。RLHF 是实现所谓 “对齐” 的关键方法。

这个过程分为两个阶段：首先，人类评估者比较成对的输出并选择更优的一个，以此训练一个 “奖励模型”，使其学习预测人类偏好。然后，AI 模型通过强化学习进行学习 —— 这是一个试错过程，当模型生成奖励模型预测人类会偏好的响应时，它会从奖励模型（而非直接从人类）获得 “奖励”。在第二阶段，模型本质上是在试图 “迎合” 奖励模型以获得更高分数。

[这是一份出色的指南，此外还有关于 RLHF 的技术深度解析](https://youtu.be/T_X4XFwKX8k)

### **Prompt engineering（提示词工程）**

提示工程是为人工智能模型设计问题（即 “提示”）以使其生成更优质、更有用响应的艺术与科学。就像与人交流时，提问的措辞方式会导致回答出现显著差异一样，同一 AI 模型也会因提示的设计方式不同而产生截然不同的响应。

提示分为两类：

- **对话式提示**：即你与 ChatGPT/Claude/Gemini 等进行对话时发送的内容。
- **系统 / 产品提示**：开发者嵌入产品后台的指令，用于塑造 AI 产品的行为方式。

[这里刚推出的播客节目，其中讨论了这个话题及更多内容](https://youtu.be/eKuFqQKYRrA)

### **RAG (retrieval-augmented generation)-检索增强生成**

RAG（检索增强生成）是一种让模型在运行时能够获取其未训练过的额外信息的技术。这就好比让模型参加开卷考试，而不是仅依靠记忆来回答问题。

当你提出诸如 “本月销售额与上月相比如何？” 这样的问题时，检索系统能够搜索你的数据库、文档和知识库，以查找相关信息。然后，这些检索到的数据会被添加为原始提示的上下文，形成一个经过丰富的提示，供模型处理。这将产生更好、更准确的答案。

当你没有通过检索增强生成（RAG）为模型提供回答问题所需的上下文时，就会产生“幻觉” 。

概括来说：

- **预训练**：教会模型通用知识（和语言）。
- **微调**：使模型针对特定任务实现专业化。
- **RLHF（强化学习从人类反馈中优化）**：让模型与人类偏好保持一致。
- **提示工程**：设计更优输入的技能，引导模型生成最有用的输出。
- **RAG（检索增强生成）**：一种在运行时从外部来源检索额外相关信息的技术，为模型提供其未训练过的最新或特定任务的上下文。

[这里是关于微调、检索增强生成（RAG）与提示工程的精彩概述](https://youtu.be/zYGDpG-pTho)

### **Inference（推理）**

**推理**是模型 “运行” 的过程。当你向 ChatGPT 提问并使其生成回答时，这就是它在进行推理。

### **MCP (model context protocol)-模型上下文协议**

MCP 是最近发布的开放标准，它让人工智能模型能够轻松、可靠且安全地与外部工具交互，例如日历、客户关系管理系统（CRM）、Slack 或代码库等。在此之前，开发人员不得不为每次新集成编写自定义代码。

MCP 还赋予人工智能通过这些工具执行操作的能力，例如在 Salesforce 中更新客户记录、在 Slack 中发送消息、在日历中安排会议，甚至将代码提交到 GitHub。

目前人工智能协议的定义仍处于早期阶段，此外还有其他竞争性提案，例如谷歌的 A2A 和 BeeAI/IBM 的 ACP。


[原文链接](https://substack.com/inbox/post/153296003)